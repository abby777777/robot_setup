{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245aec40-9b71-435c-9bda-eb4e98d935e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in diffusion pusht trained out our data (this has been mounted on the docker)\n",
    "\n",
    "from lerobot.common.policies.act.modeling_act import ACTPolicy\n",
    "\n",
    "inference_time_s = 120\n",
    "fps = 10\n",
    "device = \"cuda\"  # TODO: On Mac, use \"mps\" or \"cpu\"\n",
    "\n",
    "ckpt_path =  \"/opt/pretrained_model\"\n",
    "policy = ACTPolicy.from_pretrained(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f117439-78a5-40e5-a610-5cbd78551549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move to cuda\n",
    "policy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f622a-dbcc-4e29-9ece-f8f56d6959f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the robot config\n",
    "from lerobot.common.robot_devices.motors.configs import DynamixelMotorsBusConfig\n",
    "from lerobot.common.robot_devices.motors.dynamixel import DynamixelMotorsBus\n",
    "\n",
    "leader_config = DynamixelMotorsBusConfig(\n",
    "    port=\"/dev/ttyACM_kochleader\",\n",
    "    motors={\n",
    "        # name: (index, model)\n",
    "        \n",
    "        \"shoulder_pan\": (1, \"xl330-m077\"),\n",
    "        \"shoulder_lift\": (2, \"xl330-m077\"),\n",
    "        \"elbow_flex\": (3, \"xl330-m077\"),\n",
    "        \"wrist_flex\": (4, \"xl330-m077\"),\n",
    "        \"wrist_roll\": (5, \"xl330-m077\"),\n",
    "        \"gripper\": (6, \"xl330-m077\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "follower_config = DynamixelMotorsBusConfig(\n",
    "    port=\"/dev/ttyACM_kochfollower\",\n",
    "    motors={\n",
    "        # name: (index, model)\n",
    "        \"shoulder_pan\": (1, \"xl430-w250\"),\n",
    "        \"shoulder_lift\": (2, \"xl430-w250\"),\n",
    "        \"elbow_flex\": (3, \"xl330-m288\"),\n",
    "        \"wrist_flex\": (4, \"xl330-m288\"),\n",
    "        \"wrist_roll\": (5, \"xl330-m288\"),\n",
    "        \"gripper\": (6, \"xl330-m288\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "from lerobot.common.robot_devices.cameras.configs import OpenCVCameraConfig\n",
    "from lerobot.common.robot_devices.cameras.opencv import OpenCVCamera\n",
    "from lerobot.common.robot_devices.robots.configs import KochRobotConfig\n",
    "from lerobot.common.robot_devices.robots.manipulator import ManipulatorRobot\n",
    "\n",
    "config_cam_1 = OpenCVCameraConfig(\n",
    "                camera_index = \"/dev/video0\",\n",
    "                fps=10,\n",
    "                width= 1280,\n",
    "                height = 720,\n",
    "                color_mode = 'rgb'\n",
    "            )\n",
    "config_cam_2 = OpenCVCameraConfig(\n",
    "                camera_index = \"/dev/video2\",\n",
    "                fps=10,\n",
    "                width= 1280,\n",
    "                height = 720,\n",
    "                color_mode = 'rgb'\n",
    "            )\n",
    "\n",
    "\n",
    "robot = ManipulatorRobot(\n",
    "    KochRobotConfig(\n",
    "        leader_arms={\"main\": leader_config},\n",
    "        follower_arms={\"main\": follower_config},\n",
    "        calibration_dir=\".cache/calibration/koch\",\n",
    "        cameras={\n",
    "            \"logitech1\": config_cam_1,\n",
    "            \"logitech2\": config_cam_2,\n",
    "        },\n",
    "    )\n",
    ")\n",
    "robot.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec82fe3-506e-450b-87fe-11788592f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the policy\n",
    "import time\n",
    "import torch\n",
    "import time\n",
    "from lerobot.scripts.control_robot import busy_wait\n",
    "\n",
    "\n",
    "for _ in range(inference_time_s * fps):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # Read the follower state and access the frames from the cameras\n",
    "    observation = robot.capture_observation()\n",
    "\n",
    "    # Convert to pytorch format: channel first and float32 in [0,1]\n",
    "    # with batch dimension\n",
    "    for name in observation:\n",
    "        if \"image\" in name:\n",
    "            observation[name] = observation[name].type(torch.float32) / 255\n",
    "            observation[name] = observation[name].permute(2, 0, 1).contiguous()\n",
    "        observation[name] = observation[name].unsqueeze(0)\n",
    "        observation[name] = observation[name].to(device)\n",
    "\n",
    "    # Compute the next action with the policy\n",
    "    # based on the current observation\n",
    "    action = policy.select_action(observation)\n",
    "    # Remove batch dimension\n",
    "    action = action.squeeze(0)\n",
    "    # Move to cpu, if not already the case\n",
    "    action = action.to(\"cpu\")\n",
    "    # Order the robot to move\n",
    "    robot.send_action(action)\n",
    "\n",
    "    dt_s = time.perf_counter() - start_time\n",
    "    busy_wait(1 / fps - dt_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63b205-0106-4bdb-9298-c3f769b09755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
